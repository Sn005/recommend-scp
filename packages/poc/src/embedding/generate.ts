/**
 * OpenAI Embedding Generator
 * Generates embeddings for SCP articles using OpenAI API
 */

import OpenAI from "openai";
import { env } from "../lib/env";

/** Embeddingç”Ÿæˆçµæœ */
export interface EmbeddingResult {
  articleId: string;
  embedding: number[];
  tokenCount: number;
}

/** Embeddingå‡¦ç†ã®çµ±è¨ˆæƒ…å ± */
export interface EmbeddingStats {
  totalArticles: number;
  successCount: number;
  errorCount: number;
  totalTokens: number;
  estimatedCost: number;
}

/** ã‚¨ãƒ©ãƒ¼æƒ…å ± */
export interface EmbeddingError {
  articleId: string;
  error: string;
}

/** ãƒãƒƒãƒå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ */
export interface BatchOptions {
  batchSize: number;
  delayMs: number;
  maxRetries: number;
}

const DEFAULT_BATCH_OPTIONS: BatchOptions = {
  batchSize: 10,
  delayMs: 1000,
  maxRetries: 3,
};

/** ã‚³ã‚¹ãƒˆè¨ˆç®—å®šæ•°ï¼ˆUSD per 1M tokensï¼‰ */
const COST_PER_MILLION_TOKENS = 0.02;

/** OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ */
let _openaiClient: OpenAI | null = null;

const getOpenAIClient = (): OpenAI => {
  if (!_openaiClient) {
    _openaiClient = new OpenAI({
      apiKey: env.OPENAI_API_KEY,
    });
  }
  return _openaiClient;
};

/**
 * ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ï¼ˆHTMLã‚¿ã‚°é™¤å»ã€ç©ºç™½æ­£è¦åŒ–ã€é•·ã•åˆ¶é™ï¼‰
 */
export const preprocessContent = (content: string): string => {
  // HTMLã‚¿ã‚°é™¤å»
  const withoutHtml = content.replace(/<[^>]*>/g, " ");

  // ç©ºç™½æ­£è¦åŒ–
  const normalized = withoutHtml.replace(/\s+/g, " ").trim();

  // æœ€å¤§30000æ–‡å­—ã«åˆ¶é™ï¼ˆç´„8000ãƒˆãƒ¼ã‚¯ãƒ³ç›¸å½“ã€å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ï¼‰
  return normalized.slice(0, 30000);
};

/**
 * ã‚³ã‚¹ãƒˆè¨ˆç®—
 */
export const calculateCost = (totalTokens: number): number =>
  (totalTokens / 1_000_000) * COST_PER_MILLION_TOKENS;

/**
 * æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ã®å¾…æ©Ÿ
 */
const exponentialBackoff = (attempt: number, baseDelayMs: number): Promise<void> =>
  new Promise((resolve) => setTimeout(resolve, baseDelayMs * Math.pow(2, attempt)));

/**
 * å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®Embeddingç”Ÿæˆ
 */
export const generateEmbedding = async (
  text: string,
  maxRetries: number = DEFAULT_BATCH_OPTIONS.maxRetries
): Promise<{ embedding: number[]; tokenCount: number }> => {
  const openai = getOpenAIClient();
  const processedText = preprocessContent(text);

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await openai.embeddings.create({
        model: "text-embedding-3-small",
        input: processedText,
      });

      return {
        embedding: response.data[0].embedding,
        tokenCount: response.usage?.total_tokens ?? 0,
      };
    } catch (error) {
      const isRateLimitError =
        error instanceof Error &&
        (error.message.includes("rate_limit") || error.message.includes("429"));

      if (isRateLimitError && attempt < maxRetries) {
        console.log(`  â³ Rate limit hit, retrying in ${Math.pow(2, attempt)}s...`);
        await exponentialBackoff(attempt, 1000);
        continue;
      }

      throw error;
    }
  }

  throw new Error("Max retries exceeded");
};

/**
 * è¤‡æ•°è¨˜äº‹ã®Embeddingã‚’ãƒãƒƒãƒç”Ÿæˆ
 */
export const generateEmbeddingsBatch = async (
  articles: Array<{ id: string; content: string }>,
  options: Partial<BatchOptions> = {}
): Promise<{
  results: EmbeddingResult[];
  errors: EmbeddingError[];
  stats: EmbeddingStats;
}> => {
  const opts = { ...DEFAULT_BATCH_OPTIONS, ...options };
  const results: EmbeddingResult[] = [];
  const errors: EmbeddingError[] = [];
  let totalTokens = 0;

  console.log(`Processing ${articles.length} articles in batches of ${opts.batchSize}...`);

  for (let i = 0; i < articles.length; i += opts.batchSize) {
    const batch = articles.slice(i, i + opts.batchSize);
    const batchNumber = Math.floor(i / opts.batchSize) + 1;
    const totalBatches = Math.ceil(articles.length / opts.batchSize);

    console.log(`\nğŸ“¦ Batch ${batchNumber}/${totalBatches}`);

    for (const article of batch) {
      try {
        console.log(`  Processing ${article.id}...`);
        const { embedding, tokenCount } = await generateEmbedding(article.content, opts.maxRetries);

        results.push({
          articleId: article.id,
          embedding,
          tokenCount,
        });
        totalTokens += tokenCount;

        console.log(`  âœ… ${article.id}: ${tokenCount} tokens`);
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        console.log(`  âŒ ${article.id}: ${errorMessage}`);
        errors.push({
          articleId: article.id,
          error: errorMessage,
        });
      }
    }

    // ãƒãƒƒãƒé–“ã®å¾…æ©Ÿï¼ˆæœ€å¾Œã®ãƒãƒƒãƒä»¥å¤–ï¼‰
    if (i + opts.batchSize < articles.length) {
      console.log(`  â³ Waiting ${opts.delayMs}ms before next batch...`);
      await new Promise((resolve) => setTimeout(resolve, opts.delayMs));
    }
  }

  const stats: EmbeddingStats = {
    totalArticles: articles.length,
    successCount: results.length,
    errorCount: errors.length,
    totalTokens,
    estimatedCost: calculateCost(totalTokens),
  };

  return { results, errors, stats };
};

/**
 * çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
 */
export const printStats = (stats: EmbeddingStats): void => {
  console.log("\nğŸ“Š Statistics:");
  console.log(`  Total articles: ${stats.totalArticles}`);
  console.log(`  Success: ${stats.successCount}`);
  console.log(`  Errors: ${stats.errorCount}`);
  console.log(`  Total tokens: ${stats.totalTokens.toLocaleString()}`);
  console.log(`  Estimated cost: $${stats.estimatedCost.toFixed(4)}`);
};

/**
 * ã‚¨ãƒ©ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤º
 */
export const printErrors = (errors: EmbeddingError[]): void => {
  if (errors.length === 0) return;

  console.log("\nâŒ Errors:");
  errors.forEach(({ articleId, error }) => {
    console.log(`  ${articleId}: ${error}`);
  });
};
